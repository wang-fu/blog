(window.webpackJsonp=window.webpackJsonp||[]).push([[56],{482:function(e,t,a){"use strict";a.r(t);var _=a(15),v=Object(_.a)({},(function(){var e=this,t=e._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("p",[e._v("上一篇"),t("a",{attrs:{href:"https://imwangfu.com/2025/01/to-2025.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("《跨到 2025》"),t("OutboundLink")],1),e._v("，结尾曾简单聊到AI如何影响我们的日常生活，但2024年不仅仅是生活层面的变化，而是一个 LLM 继续加速的年份。 闭源领域 openai 和 claude.ai 相互竞争， 开源领域 qwen 和 llama 无疑是明星产品， 其他还有大量诸如 deepseek、Mistral 等在开源和闭源领域同时深耕的公司， 2024 的竞争非常白热化，gpt4 级别模型能力不再被垄断。 从行业视角来看，我认为，还有一些技术和事件的意义非常重大。 本篇笔者试图回顾那些标志性事件，并深入其中和自己最相关两个方向的看法。")]),e._v(" "),t("h2",{attrs:{id:"重要的事节点"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#重要的事节点"}},[e._v("#")]),e._v(" 重要的事节点")]),e._v(" "),t("h3",{attrs:{id:"moe的大规模应用"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#moe的大规模应用"}},[e._v("#")]),e._v(" MOE的大规模应用")]),e._v(" "),t("p",[e._v("如果要从2024年AI领域的关键词开始，我的第一选择一定是MOE（Mixture of Experts）。2023年初，OpenAI被传言在GPT-4中试用了MOE技术。这种技术听上去近乎完美——通过混合多个专家模式的方式，让大模型仅调用最需要的部分参数，大幅降低计算成本。然而，这一传言始终未能被证实，于是MOE更多停留在一个“概念”的层面。")]),e._v(" "),t("p",[e._v("真正让MOE走向大众视野的，是2023年12 月底Mistral开源的8x7B MoE模型。那时候，X （原推特）被一条磁力链接刷屏。几乎所有关注AI的从业者都在讨论——MOE不再是一个传闻的概念，而是一种可以在社区中落地的技术。")]),e._v(" "),t("p",[e._v("随后，开源社区变得更加热闹。2024年初，国内公司开始快速跟进，deepseek开源了国内首个MOE模型；不久之后，Qwen宣布支持MOE架构。到2024年6月，腾讯推出了当时全球最大的MOE模型 Hunyuan-Large，整个行业对MOE技术的认可达到了高潮。")]),e._v(" "),t("p",[e._v("MOE的意义在于它直接极大缓解了大模型的资源瓶颈——“用更少的资源，完成更大的任务”。这一点，不仅对模型技术结构创新重要，对于大模型降低成本大规模普及非常重要。")]),e._v(" "),t("h3",{attrs:{id:"gpt-4o与多模态技术的竞争"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#gpt-4o与多模态技术的竞争"}},[e._v("#")]),e._v(" GPT-4o与多模态技术的竞争")]),e._v(" "),t("p",[e._v("如果说MOE是2024年的效率革命，那么多模态就是体验革命。回想一下，你第一次使用GPT-4o是什么时候？对我来说，那必定是让人兴奋又略有遗憾的体验。")]),e._v(" "),t("p",[e._v("OpenAI的GPT-4o带来了真正的大规模多模态能力——文本、图像、视频，全都囊括其中。人们热烈讨论它科幻电影Her一样的语音助手功能，而我也对这一功能充满期待。然而，OpenAI的市场策略却 “备受批评”， 虽然高调宣布了Her的高级语音功能，但一直延迟面向公众开放，直到2024年年中才逐步放开。")]),e._v(" "),t("p",[e._v("多模态技术最大的突破，在于它不仅能够“读懂”文字，还能理解复杂的图像信息。传统的OCR技术，只能提取出一段图片中的文字内容，而GPT-4o却能读出上下文的意义——比如图像中的场景、逻辑，甚至推断出其潜在的用途。这相当于给大模型赋予了“眼睛”。")]),e._v(" "),t("p",[e._v("更令人值得关注的是，这一领域迅速形成了开源闭源竞争格局。谷歌的Gemini与Meta的Llama 3、Qwen等都加入了战局，多模态AI已经不再是 openai 独有技术，而是一场巨头间的竞争。可以预见，多模态的能力将彻底改变人机交互的体验。")]),e._v(" "),t("h3",{attrs:{id:"思维连带来的-推理模型"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#思维连带来的-推理模型"}},[e._v("#")]),e._v(" 思维连带来的“推理模型”")]),e._v(" "),t("p",[e._v("早期的 chatgpt 最大的问题就是推理能力弱，特别是在数学领域倍受质疑。 o1 模型，这是一种全新的推理范式：不再是简单的生成，而是通过在模型真正输出内容前，有一个内部的自我反馈与试错，完成复杂的推理任务，最终再返回给用户。")]),e._v(" "),t("p",[e._v("第一次体验o1模型的预览版时，我的感受其实并不特别深刻。它的某些能力还不如GPT-4，回答编码能力也不如 claude 3.5 。然而，随着最近正式版的 o1更新，我感觉出 “思维链”真正展现出了潜力, 它确实可以更精准地解决一些逻辑问题，包括编程领域也能比传统模型更精确的发现细节问题，随着使用频率增加，我发现 o1 确实比 gpt4-o等模型更“聪明”。但在纯粹的文本生成，o1依旧非常生硬，这种专注推理，而不仅仅是生成一段好听的文字，被视为“推理模型”。")]),e._v(" "),t("p",[e._v("这一技术浪潮很快席卷了开源社区。国内的Qwen团队发布了支持推理任务的qwq模型，DeepSenK也推出了推理能力增强的DeepSeek-R1，至于 openai 最新的至于 o3 其高成本模式下可以解决数学领域的难题，一直被陶哲轩点赞。这种推理能力的进步，意味着AI开始迈向“精确决策”的时代——对许多复杂场景来说，我认为这是一种真正的质变。")]),e._v(" "),t("h3",{attrs:{id:"ai普惠大众-成本必须继续大幅下降"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#ai普惠大众-成本必须继续大幅下降"}},[e._v("#")]),e._v(" AI普惠大众——成本必须继续大幅下降")]),e._v(" "),t("p",[e._v("回顾 2024 年，“成本” 是不可忽视的主题。这一年，大模型成本显著下降。OpenAI 的 GPT-4o 相较于 GPT-4，API 成本降低了十倍以上，国内厂商更是在价格战中实现了 90% 以上的降幅。这里原因有在算法上的优化，也有大模型蒸馏技术的成熟。")]),e._v(" "),t("p",[e._v("成本的下降对行业意义重大，但目前来看，成本仍是 LLM 落地的重要障碍。市面上低价模型多为 7B 或 14B 参数规模，能力有限。而像 Qwen-72B 这样的高质量大模型，其 API 费用依然较高，每百万 token 通常需要几元到几十元不等。笔者曾用 Qwen-72B 官方 API 测试代码自动化推理，仅几个小时便花费了几十到上百元。如此价格，难以支撑数千万甚至上亿用户的高质量需求。当前，GPT-4 级别模型的 C 端用户成本每月会员定价都到上百人民币（比如openai和cluade.ai的会员）， 宣称免费版本则多为小参数模型。")]),e._v(" "),t("p",[e._v("除价格外，推理速度的限制也严重影响用户体验， 我测试过许多低价 API 因推理速度过慢，实际难以实用。而推理速度和模型高成本的根源，归结到底是底层芯片的高价。英伟达凭借其算力芯片支撑了行业发展，也维持了其巨大的市值。 未来，GPU 能否进入“白菜价”时代，将决定 AI 是否能真正普惠大众。")]),e._v(" "),t("h3",{attrs:{id:"prompt提示词的工程生态初步成型"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#prompt提示词的工程生态初步成型"}},[e._v("#")]),e._v(" Prompt提示词的工程生态初步成型")]),e._v(" "),t("p",[e._v("2024 年初我介绍过，Prompt提示词技术。不是简单的 “一句提示词”，而是各种框架、可视化工具、编码平台、编排工作流、 知识库等提示工程系统。 如果在 2024 年初这些工具还是非常薄弱，那截止 2024 年底，基于提示词的工程生态逐渐成型，大部分个人开发者和企业都己经开始接受并重视这种工程能力。")]),e._v(" "),t("p",[e._v("面向 C 端用户，典型的比如 Coze 等让提示词应用进入小白化，甚至不少提示编排应用作者能以此获利。 面向开发者的工具更是百花齐放，从国内的 dify 到海外的 langFlow、 llamaIndex 等都提供了非常稳定的功能，在开源和闭源领域上各自占据相应的市场。")]),e._v(" "),t("p",[e._v("提示工程的生态非常重要，想要让 LLM 应用的构建像下饺子一样快速产生，比如拥有提示词管理、流程编排、记忆管理、知识库管理等各种成熟的配套工具，但目前仍然只是初步生态，在易用性和成熟度上仍未取得很好的进展。")]),e._v(" "),t("h3",{attrs:{id:"agent技术的突破与应用"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#agent技术的突破与应用"}},[e._v("#")]),e._v(" Agent技术的突破与应用")]),e._v(" "),t("p",[e._v("这一年， Agent技术（如自动化任务代理）在学术界和工业界得到了广泛的实验性探索，它能够在无需人类干预的情况下，跨多个系统和数据源完成复杂任务。2024 年上半年 swe-bench 的发布是一个关键节点，这是用于衡量 Agent 模拟人类程序员在开放软件领域的效果。自从普林斯顿发布这一指标，并给出 swe-Agent 方案后，上半年各类软件 Agent 层出不穷，它们大体都是模拟人的思路不断以迭代、试错的方式去完成需求和解决 bug。到了下半年，openai 也加入了这一战场，并提供了一个优化版本的 WE-bench Verified,，用于评估推理模型 o1。")]),e._v(" "),t("p",[e._v("除了软件智能体外，用于完成人类通用认为的智能体也不断探索，比如 claude.ai 发布 compute use 模拟人类操作电脑， 随后 google 在发布会也演示了类似的概念。openai 则计划发布 “Operator”的自主计算机控制代理。截止 2024 ，自主决策通用 Agent 目前停留在“探索”阶段，实用性仍然待提高，这里既有成本的考虑，也有性能的问题。")]),e._v(" "),t("h2",{attrs:{id:"再度思考提示词应用平台和-agent-技术"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#再度思考提示词应用平台和-agent-技术"}},[e._v("#")]),e._v(" 再度思考提示词应用平台和 Agent 技术")]),e._v(" "),t("p",[e._v("笔者上半年的精力在提示工程编排系统，下半年则投入在自主决策的 Agent 探索。不得不在深入回顾下这些技术的应用和局限。")]),e._v(" "),t("h3",{attrs:{id:"提示词工程化-产品化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#提示词工程化-产品化"}},[e._v("#")]),e._v(" 提示词工程化 =! 产品化")]),e._v(" "),t("p",[e._v("提示词工程化不等于应用产品化。工程化的目的是提高系统的可复用性、产品化是提供用户价值性。 我们从目标用户的视角出发，哪些人会用提示词编排平台，哪些人不会用？ 对于大多内部系统， 第一直觉用户会是开发者。 但我们发现在一些早期 LLM 应用落地的时候，开发使用可视化的编排系统意愿并不强烈，甚至会出现抵触，原因是基于裸写代码是更符合习惯，可视化平台反而需要一定学习成本。另外一个视角则是，很多开发者都有一种 “掌控” 程序逻辑的偏好，将编码逻辑置于外部系统，相当于自己失去了代码的灵活控制权，很多优化无法有效进行。")]),e._v(" "),t("p",[e._v("当然，这表面上看是一个内部系统使用意愿的问题，本质是产品本身能否提供更高开发效率的问题。")]),e._v(" "),t("p",[e._v("比如，对于一个简单的提示词应用，直接手写一个 prompt ，直接调用 LLM接口即可，中等复杂的提示，则是基于之前的结果进行串行链式再调用，一个熟悉编码的人，手写一段类似逻辑非常快，并无太多难度。在更复杂的如知识库 RAG等场景，知识拆解、检索查询、召回等有大量优化问题，可视化平台无法提供最新的策略。也就是提示词工程平台并不一定能给开发提高效率，对于一些特定场景可能是负担。")]),e._v(" "),t("p",[e._v("如果我们给运营和产品同学使用呢？提示词编写涉及大量提示词优化，链式调用可能涉及 HTTP请求、数据编码解码问题，实际上，不具备软件工程能力的产品很难胜任这类平台。")]),e._v(" "),t("p",[e._v("所以，我认为当下，在企业内部系统构建类似的内部平台，要慎重考虑。内部系统和面向 C 端系统的重要区别在用户量，前者是用户量少且重复应用场景非常少，后者用户量非常大，重复应用场景大，工程抽象的价值也大。我们虽然构建了平台，但应用产品的本身价值才是用户价值。")]),e._v(" "),t("p",[e._v("在当下阶段，对于一个中等规模的企业内部，最重要的仍然是发现 LLM 本身的应用能力，直接给用户带来价值的 LLM 工具，而不是构建 LLM工具的工具。 （备注： 这一结论是和笔者在 "),t("a",{attrs:{href:"https://imwangfu.com/2024/03/llm-engineering-future.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("2024 年初的一下观点"),t("OutboundLink")],1),e._v("是相反的）")]),e._v(" "),t("p",[e._v("但这并不代表大模型提示词工程工具没有意义， LLM 工程化形态不断在进化，提示词编排不是全部，诸如向量库、RAG知识检索、chatbi 等各种其他工具能力都值得考量。")]),e._v(" "),t("h3",{attrs:{id:"复杂-有效"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#复杂-有效"}},[e._v("#")]),e._v(" 复杂 =! 有效")]),e._v(" "),t("p",[e._v("这里我借鉴了 claude.ai 他们的一个年度回顾观点，其中提到。")]),e._v(" "),t("blockquote",[t("p",[e._v("LLM并不是构建最复杂的系统， 而是关于根据你的需求构建正确的系统")])]),e._v(" "),t("p",[e._v("在构建 Agent 技术，笔者颇有感受。 2024 年学术界和行业出现各种层出不穷的 Agent 技术，他们大多在追随一些指标的性能。 但实际上，在产品落地到特定领域的时候，我们可能有更高效和更敏捷的方案。")]),e._v(" "),t("p",[e._v("比如定位一个确定上下文的代码报错，通常只需要把相关行数给到大模型，而非需要运行复杂的 Agent 策略。 在一些特定场景，人类知晓其最佳运行流程以及确定的逻辑，那通过提示词编排 workfolw 就能解决，并且达到更精确的效果。")]),e._v(" "),t("p",[e._v("也就是通用 Agent 不应该一开始成为目标，应该优先考虑特定领域的大模型策略。只有当特定领域无法解决，能明确 Agent 能提升效果才引入到系统。这个想法似乎不符合软件设计领域的通用性，这是目前的 LLM 模型成本和性能限制导致的。 传统的软件设计通用性是 100% 精确的逻辑，而在特定领域用通用的大模型 Agent 策略， 意味着更高的不确定性（幻觉、试错），以及更高的成本。")]),e._v(" "),t("p",[e._v("什么场景下适合用 Agent 策略？ 在不能预测将要进行的步骤、以及无法进行硬编码的开放式问题。这类问题比如定位一个上下文未知的 bug，探索一个未知系统等。")]),e._v(" "),t("h2",{attrs:{id:"llm应用和-agent会去哪里"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#llm应用和-agent会去哪里"}},[e._v("#")]),e._v(" LLM应用和 Agent会去哪里")]),e._v(" "),t("p",[e._v("在 C 端领域，日活最高的几个大模型知名应用，如ChatGPT、Bing、perplexity等属于聊天和搜索等通用应用；垂直领域的明星有 Canva 、Cursor等，前者基于AI推出了一站式的AI设计创作工具套件，后者围绕 AI ，提高了软件编码的的效率。")]),e._v(" "),t("p",[e._v("企业 B 端的应用场景基本围绕特定垂直领域提供 AI能力，典型的有智能客服，检索问答，数据分析，内部代码生成等。这些领域都属于 AI增强型，即在传统应用形态下，用 LLM增强智能化。垂直领域的智能化价值非常明显，它以一种点对点、而非通用的方式提高办公效率， 未来这种增强还会持续扩大，并形成企业内部 LLM 强化的应用群。")]),e._v(" "),t("p",[e._v('而Agent技术虽然在2024年取得了突破性进展，但离真正的 "替代人类"还有很长的路要走。 人类世界的复杂性操作不仅仅涉及简单的 “知识和推理”，更多是困难在于人与人协作，人类工程师会主动和产品了解项目，和开发交接人反复讨论细节，甚至参杂大量人类情绪因素。在通用 Agent全自动化过程中， AI 会缺失大量 “人性” 的东西，它不可能简单的替代人，但我们的工作方式肯定会因为 Agent 能力的强大而被改变。')]),e._v(" "),t("p",[e._v("结尾时，笔者再提一个使用 windsurf 以及 cursor 策略。 在大多数软件任务中，我会尽可能的这样使用 AI 。（windsurf 和最新 cursor是分别两款有 Agent 能力的IDE）")]),e._v(" "),t("blockquote",[t("p",[e._v("先提供多的XXX上下文，然后再补充一句：”请你解决该任务，当你发现解决该任务的相关背景和上下文不够足以解决该问题，请你主动向我请求你需要的内容，直到你认为得到了解决该问题的全部资料。“")])]),e._v(" "),t("p",[e._v("Agent 模式下，AI 会自动分析项目，当发现解决不了，还会像我请求，最终我提供信息给 AI ，笔者大多软件编码问题，都是 AI 自动完成的。")]),e._v(" "),t("p",[e._v("个人认为，在Agent 领域，未来有两个明确方向，第一是底层LLM以及 Agent 能力越来越强大。 另一层是在产品设计上， 正如我在使用各类AI工具时的体会，最理想的状态是AI能主动交互、反复核验、精准理解，但同时保持人类在决策链条中的主导地位。")]),e._v(" "),t("p",[e._v('LLM技术的发展不应该是简单地追求"全自动化"，而是要找到AI与人类协作的最佳平衡点。在这个过程中，降低使用成本、提升推理能力、优化交互体验都是重要点。而对于开发者和企业来说，如何在通用性和专用性之间找到平衡， 如何让AI真正服务于具体的业务场景，可能才是更值更多的探索和实践。')])])}),[],!1,null,null,null);t.default=v.exports}}]);