---
title: 大模型应用工程业界方案调研及规划
date: 2024-03-15 16:22:00
type: post
blog: true
description: 在很多人认为 LLM 是收割，是泡沫的时候，但LLM 大量工程化方案已经层出不穷，这是创业公司的机会，也大公司继续延伸的关键。
tags:
    - LLM
    - 工程化
    - Agent
    - 产品化
---

( 3月份未完成草稿箱找到的调研，来续上了)

## 楔子
之前一篇 大模型应用工程现状和未来 的初衷是在 LLM 应用落地过程中，遇到切身的开发、调试、部署阻力，然后尝试寻找解决方案，然而，这种 LLM 切身的阻力在内外都很难被得到共鸣， 最大的原因是大部分开发者和公司都在探索的初期。



就像 IOS 应用刚刚出现，你遇到一个开发 IOS 难点，痛点的问题，但此时塞班机仍然是主流，大家不 care。虽然 LLM 是一个热点，但真正的应用开发领域真的非常冷门，从业者通常容易陷入“自嗨”，而旁观者则“观望”， 在和不同的开发、产品等接触下来，会发现，大部分人仅仅通过“媒体”接受信息，LLM 行业信息差仍然非常大。 这即可以被人用来“谋利”，也可能是 LLM 推进的阻力。



首先，收割小白的这种“不道德”谋利，我们不讨论。直接说行业相关信息，大量中大型公司开始布局 LLM 工程化，从我这里了解的，海外布局工具的公司更多，包括微软等都在大量招聘相关人员，而国内也有不少在跟进中，但大部分处于“开始阶段”。

![](../../assets/2024-05-23-20-40-01.png)


![](../../assets/2024-05-23-20-40-10.png)




这绝对不是简单的“风头”。 过于几乎所有的开发工具，包括 vc++/vscode 系列、苹果生态系列、linux 系列等都是以美国为主导的公司进行先行探索和投入完成后，其他国家的开发者才应用。而这次大模型应用生态的工具，中美几乎是在并行探索阶段（截止目前 LLM火爆才一年），目前也没有到哪家主导 LLM 生态的地步。我想表达的是，尝试应用落地，不管是对公司的科技产业布局还是开发者个人而言都是一种巨大的机会，而这场变革中，大公司反应迟缓，中小公司也会拥有主导的优势。





## llm 应用落地工程化是必要的


传统的 LLM 应用开发两条路，第一是直接用诸如 python、javascript 等编程语言裸写 llm 逻辑，并直接发起 http 请求调用基座 api ；另一条是借助 langChain 工具套件快速搭建 llm 逻辑。但是这两种方案都难以解决更高效的调试、测试、发布等问题。

以 web 前端的工程化（其他开发生态类似）举例子，理论上你不需要借助任何配套工具完成前端的开发，手写 html + javascript ，再自己维护代码依赖关系，自己处理图片、css 、字体等资源，最后再做代码压缩和优化等，再自己把静态文件用 ftsp 上传到服务器。但现代前端开发已经完全有各种更编辑的配套工具，帮你完成这些事情，比如 webpack 等生态本质上就是工程化的过程。



由于业务的性质，我们的场景非常适合与 LLM 结合，但发现 LLM 应用大部分是集成在现有产品功能之中，一个 LLM 化的 APP ，可能是由大量微小且独立的 LLM 小应用组成，这些微小的 LLM 应用或是独立、或是相关。



由于 LLM 是基于自然语言的 prompt，我们需要对 LLM 交互进行调优，为了达到最佳效果，我们需要 给每个独立的 LLM 小应用去进行开发、调试、测试、发布、监控，而这样的小 LLM 数量巨大，可维护性会成为灾难。

这个过程并不是简单的调整提示词，不了解的同学可以参考我之前的“大模型应用工程现状和未来”LLM 落地的常见误区小节。 LLM 应用通常是由多个 LLM chain 以“变化万千”组合调用 + 复杂的 Agent 交互逻辑组成，大量场景是需要自己反复设计，测试、验证，最终得到在特定业务场景中准确率更高的 Agent 组合。

langChian 背后及其团队是这个领域的开山鼻祖，他们尝试用 langChian + langServer + LangSmith 解决 LM 构建、调试、发布、监控等整个过程，但这只是一种思路。不管底层 LLM 能力如何，LLM 工程化一定是未来大模型必不可少的环节。



## 部分行业方案对比


### LangChain + LangServer + LangSmith
LangChain 是一个模块化框架，帮助开发者快速构建和原型化基于大语言模型（LLM）的应用。LangServer 允许将 LangChain 应用部署为 REST API，提供自动文档生成和监控功能。LangSmith 提供调试、测试和监控平台，全面提升应用的可观察性和性能。

点评：LangChain 系列工具非常强大且功能齐全，但对初学者而言可能过于复杂。适合那些需要深度定制和全面管理 LLM 应用的大型企业。生态集成度高，但便捷度稍逊一筹，开发灵活度极高​ (LangChain)​​ (Introduction | ️ LangChain)​​ (LangChain Blog)​​ (Qubitpi)​。

### PromptFlow
PromptFlow 是一个专注于提示（prompt）优化和管理的工具，支持创建、调试和优化复杂的提示工作流。它集成在了 vscode 中，并提供强大的评估功能，通过大数据集测试模型性能，集成 CI/CD 系统确保工作流质量。PromptFlow 还支持快速原型制作和云端部署，使开发者能够高效地构建和管理 LLM 应用。

点评：PromptFlow 非常适合频繁调整和优化提示的场景，特别是对提示词有严格要求的应用。特点是微软出品，并和vscode 结合， 开发，便捷度高，生态集成度中等，开发灵活度较高，但更适合特定的应用场景​ ，不合适小白。(Microsoft Learn)​​ (GitHub)​​ (Prompt Engineering)​。

### LangFlow
LangFlow 是基于 LangChain 构建的图形用户界面工具，提供直观的拖拽界面，使用户能够轻松创建和调整 LLM 应用工作流。它支持多种语言模型，提供灵活的组件库和自定义组件功能，帮助用户快速构建复杂的语言处理工作流。

点评：LangFlow 通过图形化界面大大降低了使用门槛，非常适合需要快速开发和调整的用户。便捷度高，生态集成度高，开发灵活度也很高，是综合表现非常均衡的工具。但完全对标 langChain 抽象了可视化，这种抽象不一定是最佳实践。​ (Langflow Docs)​​ (Analytics Vidhya)​​ (Langflow Docs)​。

### BootPress
BootPress 是一个生成式 AI 平台，专注于构建和部署由 LLM 驱动的聊天机器人。它提供直观的拖拽界面，丰富的预构建集成和模板，以及一键部署和多渠道发布功能。BootPress 强大的分析工具和持续监控能力，帮助优化机器人的性能和用户体验。

点评：BootPress 对于需要快速构建和部署聊天机器人的用户来说非常友好，界面简洁且功能强大。UI 组件抽象比LangFlow 更小白，脱离langChian 的绑定， 便捷度非常高，生态集成度高，但开发灵活度稍弱，主要适用于特定的聊天机器人场景​ (ChatGPT AI)​​ (ChatGPT AI)​​ (ChatGPT AI)​。

### Dify
Dify 是一个开源 LLM 应用开发平台，提供直观的工作流构建工具、丰富的模型支持和强大的 RAG 功能。它允许用户定义和管理复杂的任务流程（今年才提供 flow 能力），支持多种索引类型和高级检索策略，并提供全面的后端 API，简化 AI 集成和管理。

点评：Dify 在数据管理和高级检索方面表现出色，非常适合需要处理大量数据和复杂查询的用户。便捷度中等，生态集成度高，但目前组件还是比较少，和前面几个相比，编排能力更弱，但界面更小白，是一个更均衡的工具​ (Welcome to Dify! | English | Dify)​​ (Welcome to Dify! | English | Dify)​​ (GitHub)​。

### LlamaIndex
LlamaIndex 是一个数据框架，帮助开发者将多种数据源与 LLM 集成。它支持高级检索策略、多种索引类型和强大的 RAG 管道，优化大规模数据集的管理和利用。LlamaIndex 还提供灵活的代理系统和无缝的技术平台集成，使开发者能够高效地构建和部署智能化的 AI 应用。

点评：LlamaIndex 非常适合需要处理复杂数据和高级检索的企业用户。便捷度中等，生态集成度高，开发灵活度高，但需要一定的技术背景​ (LlamaIndex)​​ (The AI-first Infra Platform)​​ (Nanonets)​。（注：吴恩达提供了合作的课程）

### Coze
Coze 是一个面向下一代 AI 聊天机器人开发的平台，提供丰富的插件和扩展功能、知识管理、长期记忆、任务调度和多代理模式。它通过直观的界面支持复杂任务流程定制，并能与多种应用无缝集成，适用于各行业的智能化聊天机器人开发和部署。

点评：Coze 对于需要快速开发和部署多功能聊天机器人的用户来说是一个理想选择。便捷度非常高，生态集成度高，开发灵活度中等，非常适合非技术用户​ (AI Tools Explorer)​​ (Mistral 7B)​​ (BestAITo)​。

### 综合对比
便捷度：Coze > BootPress > Dify > LangFlow >PromptFlow > LlamaIndex > LangChain 系列
生态集成度：LangChain 系列 > LangFlow > Coze > BootPress > Dify > LlamaIndex > PromptFlow
开发灵活度：LangChain 系列 >LlamaIndex > LangFlow > PromptFlow > Dify > Coze > BootPress
每个工具在不同的维度都有其独特的优势，开发、产品可以根据自身需求选择最适合的方案，以最大化利用这些工具的优势。





## 对现状仍不太满意
说实话，上面的每个产品都体验过，还没有一个完全切合我想要的形态，在小白性和强大开发能力中总是缺乏平衡。

让 LLM 工具将更加注重用户体验，降低开发门槛，例如，类似于 LangFlow 和 Coze 这样的工具已经在这方面进行了尝试，但仍有提升空间。

理想的特性：

- 图形化界面：简洁直观的界面，支持拖拽操作，用户无需理解 LLM 的背景即可构建复杂的工作流。
- 预构建模板：提供丰富的预构建模板和组件，用户可以快速导入并定制，缩短开发周期。
- 一键部署：支持一键部署和多渠道发布，使得应用从开发到上线的过程更加流畅。

### 专家模式的灵活性
同时，工具也需要为高级用户提供强大的专业控制选项。这包括高级调试、深度定制和性能优化等功能，使得专业开发者能够充分发挥 LLM 的潜力。例如，LangChain 和 Dify 提供了丰富的 API 和高级调试工具，但需要进一步优化用户体验。

理想的特性：

- 高级调试工具：提供详细的日志记录和性能监控，帮助开发者深入理解和优化模型。
- 灵活的 API 接口：允许开发者通过编程接口进行深度定制和集成，满足复杂的业务需求。
- 可扩展性：支持插件和扩展功能，开发者可以根据需要添加自定义功能和优化算法。

### 结合两者的理想工具
一个理想的 LLM 工具应该结合这两者的优势，既能提供简洁易用的界面，帮助小白用户快速上手，也能提供专业的控制选项，满足高级用户的深度需求。这种工具应该具备以下特点：

- 多层次用户支持：不同层次的用户界面和功能模块，从基础操作到高级调试一应俱全。
- 灵活的集成选项：支持与多种平台和工具的无缝集成，包括现有的开发框架和第三方服务。
- 持续的社区和生态系统：活跃的用户社区和丰富的文档支持，帮助用户解决问题并不断改进工具。

- 专家模式（当下很多用编码偷懒，但其实是需要类似langchain这样的抽象，langflow做到了，但它又缺乏小白简化版）和小白模式（上面的产品我没有看到一个比较友好，bootpress相当贴近小白化一点）行为抽象是一个非常有挑战点工作，未来，我们期待从产品和开发中找到平衡点的工具，最好是一套开发者模式，一套产品模式。这不仅会大大提升开发者的生产力，也将推动 AI 技术在各个行业的广泛应用和快速发展。

