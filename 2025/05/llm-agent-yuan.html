<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <title>将 LLM Agent 大规模用于百万级数据治理—「元数据补全」 | 混沌随想</title>
    <meta
      name="keywords"
      content="将 LLM Agent 大规模用于百万级数据治理—「元数据补全」 | 混沌随想,专注 web 前端技术和通用软件架构,独立思考的软件工程师,研发效能,代码整洁,vscode,javascript,rust"
    />
    <!-- 这个是对 www  的校验，后面不需要了， www 重定向到不带 www --> 
    <meta name="baidu-site-verification" content="code-4W4K0O9eo0" />
    <meta name="google-site-verification" content="9eboClR0-Z_Vev1mKebNKCT5T2x97YNwB5n19DNao28" />
    <!-- 不带 www --> 
    <meta name="baidu-site-verification" content="code-x9cZsWaFIx" />
    <meta name="generator" content="VuePress 1.9.7" />
     <meta name="description" content="将 LLM Agent 大规模用于百万级数据治理—「元数据补全」">  <link rel="preload" href="/assets/css/0.styles.0dc98de6.css" as="style"><link rel="preload" href="/assets/js/app.32403bab.js" as="script"><link rel="preload" href="/assets/js/3.8dc51a7a.js" as="script"><link rel="prefetch" href="/assets/js/10.51147c62.js"><link rel="prefetch" href="/assets/js/100.b1492abc.js"><link rel="prefetch" href="/assets/js/101.e82c4447.js"><link rel="prefetch" href="/assets/js/102.0a584c97.js"><link rel="prefetch" href="/assets/js/103.175877ad.js"><link rel="prefetch" href="/assets/js/11.fdb2f0cc.js"><link rel="prefetch" href="/assets/js/12.0a30ed29.js"><link rel="prefetch" href="/assets/js/13.f69e82b2.js"><link rel="prefetch" href="/assets/js/14.4e4885bc.js"><link rel="prefetch" href="/assets/js/15.d027296f.js"><link rel="prefetch" href="/assets/js/16.38f3b7aa.js"><link rel="prefetch" href="/assets/js/17.5f0cd1ef.js"><link rel="prefetch" href="/assets/js/18.72085d04.js"><link rel="prefetch" href="/assets/js/19.a835b78a.js"><link rel="prefetch" href="/assets/js/20.c771a601.js"><link rel="prefetch" href="/assets/js/21.8070a6a4.js"><link rel="prefetch" href="/assets/js/22.f22f0ee9.js"><link rel="prefetch" href="/assets/js/23.d2827f1e.js"><link rel="prefetch" href="/assets/js/24.b5dbeb2f.js"><link rel="prefetch" href="/assets/js/25.affcd6a6.js"><link rel="prefetch" href="/assets/js/26.d5d5dc29.js"><link rel="prefetch" href="/assets/js/27.fa3f3c2a.js"><link rel="prefetch" href="/assets/js/28.2cd321b3.js"><link rel="prefetch" href="/assets/js/29.e1c6d3dc.js"><link rel="prefetch" href="/assets/js/30.57138dca.js"><link rel="prefetch" href="/assets/js/31.84c0c338.js"><link rel="prefetch" href="/assets/js/32.fdc19c9e.js"><link rel="prefetch" href="/assets/js/33.3dfb865a.js"><link rel="prefetch" href="/assets/js/34.33abc3eb.js"><link rel="prefetch" href="/assets/js/35.f4f9dfee.js"><link rel="prefetch" href="/assets/js/36.52cf06ae.js"><link rel="prefetch" href="/assets/js/37.394472e1.js"><link rel="prefetch" href="/assets/js/38.d9311661.js"><link rel="prefetch" href="/assets/js/39.bb1e3134.js"><link rel="prefetch" href="/assets/js/4.8d6e4007.js"><link rel="prefetch" href="/assets/js/40.f5390aba.js"><link rel="prefetch" href="/assets/js/41.ebe29e43.js"><link rel="prefetch" href="/assets/js/42.1fccbe7a.js"><link rel="prefetch" href="/assets/js/43.28e14c5f.js"><link rel="prefetch" href="/assets/js/44.ee7f7ee0.js"><link rel="prefetch" href="/assets/js/45.58bdca2a.js"><link rel="prefetch" href="/assets/js/46.bccd73d4.js"><link rel="prefetch" href="/assets/js/47.0241f1e0.js"><link rel="prefetch" href="/assets/js/48.8d645d97.js"><link rel="prefetch" href="/assets/js/49.aca5f8fc.js"><link rel="prefetch" href="/assets/js/5.7f3f9f22.js"><link rel="prefetch" href="/assets/js/50.b67ec2dd.js"><link rel="prefetch" href="/assets/js/51.9b0117bd.js"><link rel="prefetch" href="/assets/js/52.ec3e1e4c.js"><link rel="prefetch" href="/assets/js/53.fc157c97.js"><link rel="prefetch" href="/assets/js/54.479c0197.js"><link rel="prefetch" href="/assets/js/55.3ac12af8.js"><link rel="prefetch" href="/assets/js/56.cecd7a4a.js"><link rel="prefetch" href="/assets/js/57.8bf80825.js"><link rel="prefetch" href="/assets/js/58.7b86775f.js"><link rel="prefetch" href="/assets/js/59.37078ed4.js"><link rel="prefetch" href="/assets/js/6.8ea32bd8.js"><link rel="prefetch" href="/assets/js/60.ed7ec107.js"><link rel="prefetch" href="/assets/js/61.8b1a595d.js"><link rel="prefetch" href="/assets/js/62.5cab2281.js"><link rel="prefetch" href="/assets/js/63.e3da29c8.js"><link rel="prefetch" href="/assets/js/64.fbd43d88.js"><link rel="prefetch" href="/assets/js/65.33b8c5db.js"><link rel="prefetch" href="/assets/js/66.f50e25d9.js"><link rel="prefetch" href="/assets/js/67.70c8f281.js"><link rel="prefetch" href="/assets/js/68.23f66319.js"><link rel="prefetch" href="/assets/js/69.1f1d799d.js"><link rel="prefetch" href="/assets/js/7.ecca50fc.js"><link rel="prefetch" href="/assets/js/70.a055c951.js"><link rel="prefetch" href="/assets/js/71.a9e657da.js"><link rel="prefetch" href="/assets/js/72.cd9b577a.js"><link rel="prefetch" href="/assets/js/73.c25c793c.js"><link rel="prefetch" href="/assets/js/74.61b6bc43.js"><link rel="prefetch" href="/assets/js/75.9957780c.js"><link rel="prefetch" href="/assets/js/76.ea128704.js"><link rel="prefetch" href="/assets/js/77.eb17d0a8.js"><link rel="prefetch" href="/assets/js/78.8eb43e7a.js"><link rel="prefetch" href="/assets/js/79.f0cdc7a5.js"><link rel="prefetch" href="/assets/js/8.d2bddb8a.js"><link rel="prefetch" href="/assets/js/80.a30cce84.js"><link rel="prefetch" href="/assets/js/81.4c8fe987.js"><link rel="prefetch" href="/assets/js/82.06c14436.js"><link rel="prefetch" href="/assets/js/83.294c9208.js"><link rel="prefetch" href="/assets/js/84.a57c16c4.js"><link rel="prefetch" href="/assets/js/85.281aa58a.js"><link rel="prefetch" href="/assets/js/86.97f202f0.js"><link rel="prefetch" href="/assets/js/87.af0c8754.js"><link rel="prefetch" href="/assets/js/88.0355a3cb.js"><link rel="prefetch" href="/assets/js/89.bcd768a3.js"><link rel="prefetch" href="/assets/js/9.fd658507.js"><link rel="prefetch" href="/assets/js/90.2a93c57c.js"><link rel="prefetch" href="/assets/js/91.b3126e8f.js"><link rel="prefetch" href="/assets/js/92.9f9ae6c4.js"><link rel="prefetch" href="/assets/js/93.458e4b06.js"><link rel="prefetch" href="/assets/js/94.e9789412.js"><link rel="prefetch" href="/assets/js/95.0d359a3b.js"><link rel="prefetch" href="/assets/js/96.8beb4bad.js"><link rel="prefetch" href="/assets/js/97.dccf438a.js"><link rel="prefetch" href="/assets/js/98.c52a218f.js"><link rel="prefetch" href="/assets/js/99.5ab798af.js"><link rel="prefetch" href="/assets/js/vendors~docsearch.a7c5c6f6.js"> <link rel="stylesheet" href="/assets/css/0.styles.0dc98de6.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/logo.png" alt="混沌随想" class="logo"> <span class="site-name can-hide">混沌随想</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="/about/" class="nav-link">关于作者</a></div> <!----></nav> <a href="/settings/" title="博客设置" class="settings-link">
      ⚙️
    </a></div></header> <div class="sidebar-mask"></div> <div class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="/about/" class="nav-link">关于作者</a></div> <!----></nav>  <ul class="sidebar-links"><li><div class="sidebar-group first"><p class="sidebar-heading open"><span>将 LLM Agent 大规模用于百万级数据治理—「元数据补全」</span> <!----></p> <ul class="sidebar-group-items"></ul></div></li></ul> </div> <div data-v-d56170a2><div class="blog" data-v-d56170a2><div class="blog__header" data-v-d56170a2><p class="publish-date" data-v-d56170a2><time datetime="2025-05-05T11:55:00.000Z" data-v-d56170a2>2025年5月5日</time></p> <!----> <h1 class="blog__title" data-v-d56170a2>将 LLM Agent 大规模用于百万级数据治理—「元数据补全」</h1></div> <div class="wechat-content html-isolated" data-v-d56170a2>
<div class="content" options="[object Object]"><h2 id="h_1902814743636447932_0" >楔子</h2><p >最近 2 个月，笔者大部分时间都在利用 AI 进行大规模补全元数据，整个流程涉及元数据加工、上下文收集、不同类型的 AI Agent 任务、AI 效果评估、提示工程调优等。</p><p >期间，从 0-1 搭建基础的框架，包括<span><a class="RichContent-EntityWord css-b7erz1" href="https://zhida.zhihu.com/search?content_id=257345605&amp;content_type=Article&amp;match_order=1&amp;q=AI+ETL&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NTI0NjUzNTAsInEiOiJBSSBFVEwiLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjoyNTczNDU2MDUsImNvbnRlbnRfdHlwZSI6IkFydGljbGUiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9._oViKx5Pw40oUUDjrfhPe664aS-VNPmY3diV8ZLmFHQ&amp;zhida_source=entity" target="_blank">AI ETL<svg width="10px" height="10px" viewBox="0 0 16 16" class="ZDI ZDI--FourPointedStar16 css-1dvsrp" fill="currentColor"><path d="m5.068 9.267-3.08-.77a.512.512 0 0 1 0-.994l3.08-.77a2.289 2.289 0 0 0 1.665-1.665l.77-3.08a.512.512 0 0 1 .994 0l.77 3.08c.205.82.845 1.46 1.665 1.665l3.08.77a.512.512 0 0 1 0 .994l-3.08.77a2.29 2.29 0 0 0-1.665 1.665l-.77 3.08a.512.512 0 0 1-.994 0l-.77-3.08a2.289 2.289 0 0 0-1.665-1.665Z"></path></svg></a></span> 加工、AI Core 层（实现各种任务和<span><a class="RichContent-EntityWord css-b7erz1" href="https://zhida.zhihu.com/search?content_id=257345605&amp;content_type=Article&amp;match_order=1&amp;q=Haystack+Pipeline&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NTI0NjUzNTAsInEiOiJIYXlzdGFjayBQaXBlbGluZSIsInpoaWRhX3NvdXJjZSI6ImVudGl0eSIsImNvbnRlbnRfaWQiOjI1NzM0NTYwNSwiY29udGVudF90eXBlIjoiQXJ0aWNsZSIsIm1hdGNoX29yZGVyIjoxLCJ6ZF90b2tlbiI6bnVsbH0.r1M0SP3Ihl5u7NDllRd7psiCXP0vFmwVSHJHDzvqCi0&amp;zhida_source=entity" target="_blank">Haystack Pipeline<svg width="10px" height="10px" viewBox="0 0 16 16" class="ZDI ZDI--FourPointedStar16 css-1dvsrp" fill="currentColor"><path d="m5.068 9.267-3.08-.77a.512.512 0 0 1 0-.994l3.08-.77a2.289 2.289 0 0 0 1.665-1.665l.77-3.08a.512.512 0 0 1 .994 0l.77 3.08c.205.82.845 1.46 1.665 1.665l3.08.77a.512.512 0 0 1 0 .994l-3.08.77a2.29 2.29 0 0 0-1.665 1.665l-.77 3.08a.512.512 0 0 1-.994 0l-.77-3.08a2.289 2.289 0 0 0-1.665-1.665Z"></path></svg></a></span>）、<span><a class="RichContent-EntityWord css-b7erz1" href="https://zhida.zhihu.com/search?content_id=257345605&amp;content_type=Article&amp;match_order=1&amp;q=API+%E4%B8%9A%E5%8A%A1%E5%B1%82&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NTI0NjUzNTAsInEiOiJBUEkg5Lia5Yqh5bGCIiwiemhpZGFfc291cmNlIjoiZW50aXR5IiwiY29udGVudF9pZCI6MjU3MzQ1NjA1LCJjb250ZW50X3R5cGUiOiJBcnRpY2xlIiwibWF0Y2hfb3JkZXIiOjEsInpkX3Rva2VuIjpudWxsfQ.1CU7SvlPTMjkhF-US92m5bMJ3gLlptOx6rtMx5bOwzg&amp;zhida_source=entity" target="_blank">API 业务层<svg width="10px" height="10px" viewBox="0 0 16 16" class="ZDI ZDI--FourPointedStar16 css-1dvsrp" fill="currentColor"><path d="m5.068 9.267-3.08-.77a.512.512 0 0 1 0-.994l3.08-.77a2.289 2.289 0 0 0 1.665-1.665l.77-3.08a.512.512 0 0 1 .994 0l.77 3.08c.205.82.845 1.46 1.665 1.665l3.08.77a.512.512 0 0 1 0 .994l-3.08.77a2.29 2.29 0 0 0-1.665 1.665l-.77 3.08a.512.512 0 0 1-.994 0l-.77-3.08a2.289 2.289 0 0 0-1.665-1.665Z"></path></svg></a></span>等跑通上线耗时 10 天左右，代码量在 1.5w 上下。初步验证后，再用一个月的时间搭建了完整的自动化评估体系，并做大量优化。整体代码量在2-3w (包括前端管理台)</p><p >整个项目 AI 代码生成量占比 95% 以上，参考之前一篇<a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzAwMzA4NDY4Ng%3D%3D%26mid%3D2448196692%26idx%3D1%26sn%3D40a19a44dc3dac0d86fe7d0a2a4eb81f%26scene%3D21%23wechat_redirect" class=" wrap external" target="_blank" rel="nofollow noreferrer" >不止是10倍，人月神话下的AI现代开发</a>。</p><p >本文将回顾，<span><a class="RichContent-EntityWord css-b7erz1" href="https://zhida.zhihu.com/search?content_id=257345605&amp;content_type=Article&amp;match_order=1&amp;q=%E5%85%83%E6%95%B0%E6%8D%AE%E8%A1%A5%E5%85%A8&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NTI0NjUzNTAsInEiOiLlhYPmlbDmja7ooaXlhagiLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjoyNTczNDU2MDUsImNvbnRlbnRfdHlwZSI6IkFydGljbGUiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9.Q-JkLxUZnZtmcOhG3mFPi7I9jWBzKj90u9iqr5mFfes&amp;zhida_source=entity" target="_blank">元数据补全<svg width="10px" height="10px" viewBox="0 0 16 16" class="ZDI ZDI--FourPointedStar16 css-1dvsrp" fill="currentColor"><path d="m5.068 9.267-3.08-.77a.512.512 0 0 1 0-.994l3.08-.77a2.289 2.289 0 0 0 1.665-1.665l.77-3.08a.512.512 0 0 1 .994 0l.77 3.08c.205.82.845 1.46 1.665 1.665l3.08.77a.512.512 0 0 1 0 .994l-3.08.77a2.29 2.29 0 0 0-1.665 1.665l-.77 3.08a.512.512 0 0 1-.994 0l-.77-3.08a2.289 2.289 0 0 0-1.665-1.665Z"></path></svg></a></span>的一些背景以及在技术层的关键要点。</p><p class="content"><br></p><figure ><div><img src="https://pic2.zhimg.com/v2-099a962b8ff6d2c9d6367151c954cedf_1440w.jpg" class="origin_image zh-lightbox-thumb" width="1856" ></div><figcaption>补充一张图</figcaption></figure><h2 id="h_1902814743636447932_1" ><span><a class="RichContent-EntityWord css-b7erz1" href="https://zhida.zhihu.com/search?content_id=257345605&amp;content_type=Article&amp;match_order=1&amp;q=%E6%95%B0%E6%8D%AE%E6%B2%BB%E7%90%86&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NTI0NjUzNTAsInEiOiLmlbDmja7msrvnkIYiLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjoyNTczNDU2MDUsImNvbnRlbnRfdHlwZSI6IkFydGljbGUiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9.y9YnoU4e8kB96I3nn3Cj35PDqoDCGjxOKOeLetNzi54&amp;zhida_source=entity" target="_blank">数据治理<svg width="10px" height="10px" viewBox="0 0 16 16" class="ZDI ZDI--FourPointedStar16 css-1dvsrp" fill="currentColor"><path d="m5.068 9.267-3.08-.77a.512.512 0 0 1 0-.994l3.08-.77a2.289 2.289 0 0 0 1.665-1.665l.77-3.08a.512.512 0 0 1 .994 0l.77 3.08c.205.82.845 1.46 1.665 1.665l3.08.77a.512.512 0 0 1 0 .994l-3.08.77a2.29 2.29 0 0 0-1.665 1.665l-.77 3.08a.512.512 0 0 1-.994 0l-.77-3.08a2.289 2.289 0 0 0-1.665-1.665Z"></path></svg></a></span>背景</h2><p >数据治理是企业对数据资产进行全方位管理的一套机制和流程，目的是确保数据质量、合规、安全性和可用。举一个简单的例子，业务想导出部分生产的数据，在合规的角度，我们必须知道这个表是否是敏感表，这个表的导出授权要经过哪些人审批等。</p><p >而元数据是数据治理的核心，由于管理规范和用户敏感信息保护，我们无法直接获取数据库中的真实数据记录，比如用户名，用户密码等。但我们可以通过管理数据库中描述数据的元数据，比如表描述、字段描述等展开管理，元数据就是描述数据的数据，在 mysql 表描述和字段描述可以在创建表和字段的时候开发同学进行定义。</p><p >然而，现实中，存在两个问题。1. 开发并未按规范在生成表和字段的时候添加注释。 2. 还有部分元数据是无法通过数据库原生的语法进行定义的，比如表的业务含义，字段加工口径，表更新方式，表更新失效，敏感等级等。这些信息带有业务含义，通常需要后期进行人工维护。</p><p >对于增量的数据，我们可以定义数据治理的管理规范，强制用户在生成表和字段的时候，人工补全这些信息。由于历史原因，存量待补全的表级数据量高达几百万，字段级数据高达上亿。这几乎不太可能全部由人工维护。</p><p >基于 <span><a class="RichContent-EntityWord css-b7erz1" href="https://zhida.zhihu.com/search?content_id=257345605&amp;content_type=Article&amp;match_order=1&amp;q=LLM&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NTI0NjUzNTAsInEiOiJMTE0iLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjoyNTczNDU2MDUsImNvbnRlbnRfdHlwZSI6IkFydGljbGUiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9.BeubgvFnFBcsWQ9xrqYqxsFJf9arcw-8IXHVxIf22m0&amp;zhida_source=entity" target="_blank">LLM<svg width="10px" height="10px" viewBox="0 0 16 16" class="ZDI ZDI--FourPointedStar16 css-1dvsrp" fill="currentColor"><path d="m5.068 9.267-3.08-.77a.512.512 0 0 1 0-.994l3.08-.77a2.289 2.289 0 0 0 1.665-1.665l.77-3.08a.512.512 0 0 1 .994 0l.77 3.08c.205.82.845 1.46 1.665 1.665l3.08.77a.512.512 0 0 1 0 .994l-3.08.77a2.29 2.29 0 0 0-1.665 1.665l-.77 3.08a.512.512 0 0 1-.994 0l-.77-3.08a2.289 2.289 0 0 0-1.665-1.665Z"></path></svg></a></span> 的元数据自动化补全由此而生。在做这个方案前<b>，</b>笔者曾经深入调查过数据治理的 AI 应用，基本都是传统的 AI 辅助生成策略 ，人工为主， <b>本篇的不少方案在数据治理业内都是首创的，特别是大规模用 AI 补全评估闭环，并对结果加以直接应用。</b></p><h2 id="h_1902814743636447932_2" >核心技术点</h2><p >当我们面对几百万表和上亿字段的元数据补全任务时，传统的人工方式显然行不通。而传统的 NLP技术仅仅是简单的字符预测补全，无法推理，大模型的诞生让这个在过去不可能完成的任务变成现实。</p><h3 id="h_1902814743636447932_3" ><span><a class="RichContent-EntityWord css-b7erz1" href="https://zhida.zhihu.com/search?content_id=257345605&amp;content_type=Article&amp;match_order=1&amp;q=%E5%A4%9A%E7%BB%B4%E4%B8%8A%E4%B8%8B%E6%96%87%E5%A2%9E%E5%BC%BA&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NTI0NjUzNTAsInEiOiLlpJrnu7TkuIrkuIvmloflop7lvLoiLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjoyNTczNDU2MDUsImNvbnRlbnRfdHlwZSI6IkFydGljbGUiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9.oNFeL9gtwDf7z6BvsPacJ8EPfiwQSMBvtRa5voHOIC8&amp;zhida_source=entity" target="_blank">多维上下文增强<svg width="10px" height="10px" viewBox="0 0 16 16" class="ZDI ZDI--FourPointedStar16 css-1dvsrp" fill="currentColor"><path d="m5.068 9.267-3.08-.77a.512.512 0 0 1 0-.994l3.08-.77a2.289 2.289 0 0 0 1.665-1.665l.77-3.08a.512.512 0 0 1 .994 0l.77 3.08c.205.82.845 1.46 1.665 1.665l3.08.77a.512.512 0 0 1 0 .994l-3.08.77a2.29 2.29 0 0 0-1.665 1.665l-.77 3.08a.512.512 0 0 1-.994 0l-.77-3.08a2.289 2.289 0 0 0-1.665-1.665Z"></path></svg></a></span>LLM推理</h3><p >如果只给LLM一个表名或字段名，它生成的描述通常只是基于名字命名，一般只是纯翻译，缺乏业务特性。比如给你看一个名为"user_info"的表名，你能猜到它存储用户信息，但具体是哪类用户？存储了哪些关键信息？这些都无从得知。</p><p >解决这个问题的关键，在构建更详细、更多维的上下文体系，这有点像给模型提供"全息视角"：</p><ul><li >不仅告诉它表名，还提供所有表结构、字段信息及其类型</li><li >不仅有字段信息，还有表之间间的血缘关系</li><li >不仅有技术信息，还有业务域知识，比如属于哪个子系统和业务</li><li >在必要情况下，还有生成当前表的上游原始 SQL</li></ul><p >举个例子，当我们处理一个名为"fund_trans_detail"的表时，我们不仅提供表结构，还会告诉模型这个表上游连接了哪些表、下游流向了哪里、它属于哪个业务系统、涉及哪类金融产品，如果这个trans_detail的下游人工注释是“贷款资金交易历史记录”，人类通常会判断 “fund_trans_detail” 表是用于贷款的一个资金交易明细。</p><p >这种立体式上下文让模型能够"站在业务视角"去理解数据，生成的描述也就更加贴近业务实际。有时候，甚至会惊讶于模型能从这些碎片化信息中推断出准确的业务场景， 这种理解能力一般的人类更细。我们验证了大量补全任务案例，特别是涉及生成 SQL 的推断场景，由于上游多层 SQL 综合影响结果，对于人类开发而言，本身是一个有挑战的预测任务。</p><p >想象给你分配一个不是你负责的表，没有注释，你必须通过上游关系，生成SQL（可能是多层），逐一推断这个表是什么含义，这对技术领域的知识广度有一定要求的。</p><p >其中有意思的一些案例是【不规范的命名表】，比如数据库中有些表是类似这样命名的，“sfzlist”, 初步看，人类有点懵逼，模型竟然能预测出 sfz 是身份证的缩写，但这种有点随缘，不规范的命名是预测失败占比最高的因素。这里也延伸出一个问题点，模型预测的准确性和“原始表的质量”正相关，比如命名规范，上下游应用规范等。观察了大部分预测失败或者效果不佳的案例，这些案例分发给人类开发（和当前表无关的开发）去看，也难以准确预测。 比如有的表命名为 loginuser_list 里面确实有用户信息，但实际因为历史债的原因，这个表已经成了“销户”用户列表～～ 这种情况，如果不深入追踪代码，基本无法预测。然而追溯代码的成本非常高，且涉及合规，以及团队协作等问题，我们并未把代码追溯作为 LLM预测的一个方案。 但能想象，在拥有代码知识的背景，AI 预测的准确性会提高，但 GPU 推理成本也会提高（Agent 迭代调用）。</p><h3 id="h_1902814743636447932_4" >多Agent专家架构</h3><p >这里的 Agent 并不是我们想象的自主决策 Agent ，仅仅是针对不同的任务，定制化不同的提示词，以及应用不同的上下文。不同类型的元数据补全任务有着不同的特点。比如，表注释补全，通常只需要基本的表结构以及上下游关系，要求 AI 补全的内容非常简洁，控制在15 字以内。 表业务含义描述需要 AI 理解一定的业务知识，理解生成SQL，描述会更加详细。所AI 预测必须是针对性调优，不同的任务不同的"Agent"。</p><p >类似医院的专科体系 - 你不会让眼科医生去做心脏手术，对吧？于是我们设计了"专家Agent矩阵"：</p><ul><li >表描述专家：擅长从上下游血缘和字段结构中推理</li><li >字段描述专家：专注解读单个字段的含义和用途</li><li >敏感等级专家：精通数据安全分类标准</li><li >更新频率专家：分析日志推断数据更新规律</li><li >表业务含义专家：擅长从宏观理解表的业务用途</li></ul><p >... ...</p><p >每个"专家"都有自己独特的提示词设计和上下文处理逻辑。通过专业分工突破单一AI的局限性，每个 Agent 专家聚焦特定的任务领域，实现更精准的模块化元数据补全。 另外 多 Agent 的好处还在于，后续我们对每个 AI 任务的准确评估以及优化。</p><h3 id="h_1902814743636447932_5" ><span><a class="RichContent-EntityWord css-b7erz1" href="https://zhida.zhihu.com/search?content_id=257345605&amp;content_type=Article&amp;match_order=1&amp;q=%E7%9F%A5%E8%AF%86%E5%A2%9E%E5%BC%BA%E4%B8%8E%E7%BA%A6%E6%9D%9F%E7%94%9F%E6%88%90&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NTI0NjUzNTAsInEiOiLnn6Xor4blop7lvLrkuI7nuqbmnZ_nlJ_miJAiLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjoyNTczNDU2MDUsImNvbnRlbnRfdHlwZSI6IkFydGljbGUiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9.BlQQCoh8TwzZaEwcGGoNIzgHo-u9Es9KsR4Q9poc_K4&amp;zhida_source=entity" target="_blank">知识增强与约束生成<svg width="10px" height="10px" viewBox="0 0 16 16" class="ZDI ZDI--FourPointedStar16 css-1dvsrp" fill="currentColor"><path d="m5.068 9.267-3.08-.77a.512.512 0 0 1 0-.994l3.08-.77a2.289 2.289 0 0 0 1.665-1.665l.77-3.08a.512.512 0 0 1 .994 0l.77 3.08c.205.82.845 1.46 1.665 1.665l3.08.77a.512.512 0 0 1 0 .994l-3.08.77a2.29 2.29 0 0 0-1.665 1.665l-.77 3.08a.512.512 0 0 1-.994 0l-.77-3.08a2.289 2.289 0 0 0-1.665-1.665Z"></path></svg></a></span></h3><p >普通的 LLM 知道什么是"客户号"、"账户"这样的通用概念，但对企业内部的特定术语如"非柜面"、"理财产品代码"等专有名词却知之甚少。</p><p >为了弥补这个差距，我们构建了企业特定的领域知识库，涵盖：</p><ul><li >金融业务术语表</li><li >内部系统缩写词典</li><li >敏感数据分类标准</li><li >表名缩写等</li></ul><p >这些知识被动态注入到提示词中，帮助模型理解特定行业和企业背景。但这里要提到一个评估（下面会讲）观察到的结果——领域知识的作用对 Agent 整体的效果不是很大。这一结果和我们预想的不一样，最终我们构建了基于 AI 自动化收集知识，一会我也会分享下原因。</p><h2 id="h_1902814743636447932_6" ><span><a class="RichContent-EntityWord css-b7erz1" href="https://zhida.zhihu.com/search?content_id=257345605&amp;content_type=Article&amp;match_order=1&amp;q=%E8%87%AA%E5%8A%A8%E8%AF%84%E4%BC%B0%E4%B8%8E%E8%B4%A8%E9%87%8F%E6%8E%A7%E5%88%B6&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NTI0NjUzNTAsInEiOiLoh6rliqjor4TkvLDkuI7otKjph4_mjqfliLYiLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjoyNTczNDU2MDUsImNvbnRlbnRfdHlwZSI6IkFydGljbGUiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9.PjYbmi9ZhTenNk0qp_CbXQMfvB8dLZrcjTwCyZcbdY8&amp;zhida_source=entity" target="_blank">自动评估与质量控制<svg width="10px" height="10px" viewBox="0 0 16 16" class="ZDI ZDI--FourPointedStar16 css-1dvsrp" fill="currentColor"><path d="m5.068 9.267-3.08-.77a.512.512 0 0 1 0-.994l3.08-.77a2.289 2.289 0 0 0 1.665-1.665l.77-3.08a.512.512 0 0 1 .994 0l.77 3.08c.205.82.845 1.46 1.665 1.665l3.08.77a.512.512 0 0 1 0 .994l-3.08.77a2.29 2.29 0 0 0-1.665 1.665l-.77 3.08a.512.512 0 0 1-.994 0l-.77-3.08a2.289 2.289 0 0 0-1.665-1.665Z"></path></svg></a></span></h2><p >最初，我们用很少的时间快速搭建了整个 Agent 自动补全的项目。但<b>随后一个多月的时间基本都在构建评估</b>，包括评估的后台，以及管理台等。没有评估，就无法度量，无法改进 prompts ，单纯的观察 1-2 个特例是无法成为优化提示词的原因，面对海量数据，必须要有自动化评估。</p><h3 id="h_1902814743636447932_7" >生成-评估-再生成闭环</h3><p >我们设计了"AI评审员"机制：用另一个经过特殊调优的评估模型来评价生成模型的输出质量。具体做法是：</p><p >1. 利用已有人工标注的元数据，或者已经有人类标注的数据（对于表描述和字段描述历史数据有存量的数据）</p><p >2. 遮掩人工标注的答案，让不同的 Agent 策略分别重新生成</p><p >3. 基于 AI 生成的结果和人工标注的答案，让评估模型判断元数据的好坏</p><p >4. 挑选平均得分最高的 Agent 策略。</p><p >选择范围配置 → 选择任务类型 → 选择提示词和评估提示词 → 启动评估 → 监控评估进度 → 查看评估结果 → 应用最佳提示词</p><p class="content"><br></p><figure ><div><img src="https://pic4.zhimg.com/v2-e2a3b681d5ab7f6a07ddc77276c336ff_1440w.jpg" class="origin_image zh-lightbox-thumb" width="3626" ></div><figcaption>评估流程</figcaption></figure><div class="highlight"><pre><code class="language-text">评估提示词大概是这样的你是一个资深数据库评估专家，现在需要你评估元数据库AI 生成和人工标注的一致性。
评估内容:
1. 原始内容: {original}
2. AI预测的内容: {predicted}
请根据以下标准评分(0-100分):
- 90-100分: 完全准确，且解释更清晰（包含了字段用途、业务含义等）
- 70-89分: 基本准确，核心含义一致
- 50-69分: 部分准确，但有遗漏或偏差
- 0-49分: 描述不准确或完全无关
请只返回一个数字分数，不需要其他解释。
————————
【以上简化版提示词仅仅参考示例】</code></pre></div><p class="content"><br></p><p >我们建立了0-100分的评分体系，设定一定的优化目标以及优化时间成本，当某个任务优化到一定阶段，分数无法增长时，通常就会降低在某个任务的优化投入。</p><p >前面我们提到过，业务提供的知识库对 Agent 预测的结果并无效果。这是因为这些知识过度关注上层概念，比如表命名规范，常识性缩写。这些知识是从业务的视角常规的知识，但开发在数据库建表的过程真正遵守了？从这个规范是否能推断出含义？ 实际上难倒模型补全的是这些开发在写代码过程的“私有知识”，比如拼音缩写“sfz”代表身份证，qq_applay代表手支付。这种东西通常是一个团队内的开发同学才能知道。 但我们无法一对一地收集这些知识。</p><p >于是在构建评估的过程，我们尝试自动优化的策略。即由 AI 生成知识库，并自动注入提示词，再评估——再生成——再评估的流程。</p><h3 id="h_1902814743636447932_8" >自动归因及知识生成</h3><p >AI 自动化生成知识库有两个策略。</p><ul><li ><b>基于符号分割表/字段名获取高频率缩写。</b></li></ul><p > 比如 abc_name_list 自动拆分成 abc、name、list，然后统计在一定范围（比如部门，团队等）数据库表和字段的频率最高的 top 缩写（比如前 1000 个）。然后再排除掉常见的词汇（比如 id、name等），剩下的 top 高频缩写待生成知识。</p><p >生成知识的过程：基于缩写反向查表追溯到被使用到的原始表和原始字段以及相关注释，让 LLM 预测这个缩写的含义。</p><p >提示词大概如下</p><p class="content"><br></p><div class="highlight"><pre><code class="language-text">你是一个专业的数据库命名规范专家，帮助用户解析数据库中的缩写含义。   请根据以下上下文信息，推测缩写 {{ context(abbreviation) }}最可能的完整含义。 
请仅回答这个缩写代表的完整词语或短语，不要有任何解释、引导语或标点符号。   
上下文信息： {{ context(related_tables) }}   
请给出缩写{{ context(abbreviation) }}的完整含义
【以上简化版提示词仅仅参考示例】</code></pre></div><ul><li ><b>Agent 归因 模式——基于 bad_case 自动生成知识。</b></li></ul><p >在评估环节，自动把打分较低的案例收集起来，其中包括 AI 预测的结果，人类标注的结果，以及表的相关上下文信息，让另一个 AI 分析，需要增加哪些知识，才会让 AI 的结果更准确，以替代人类的知识标注。</p><figure ><div><img src="https://pica.zhimg.com/v2-bea2a64f50c46f6e716f3fcd682ddc74_1440w.jpg" class="origin_image zh-lightbox-thumb" width="3692" ></div></figure><p >提示词大概如下</p><div class="highlight"><pre><code class="language-text">你是一位数据库知识提取专家，在帮我们分析大模型生成表描述/字段描述中失败的关键知识缺失。
请分析以下多个错误预测案例，识别出导致预测失败的共同关键缩写词（表名中的缩写），或者关键知识点（比如表的单词组合），并给出它们的真实含义。
举一个例子：
... ... more ... ...
我们把这些关键影响 AI 预测的因素，当成需要提取的 "知识"，或者缩写。
以下是从 AI 预测的结果表中取出需要被分析的案例：
{{ context('cases_text') }}
请综合分析以上案例，按如下格式返回识别出的关键缩写词或者知识术语，提高大模型预测得分:
``` json
{
  "analysis": "一步一步分析每个案例，AI 会预测失败的原因，推理补充哪些知识，将会对 AI 的预测产生帮助",
  "result": [
    {
      "abbreviation": "知识名/缩写词1",
      "meaning": "含义1"
    },
    {
      "abbreviation": "知识名/缩写词2",
      "meaning": "含义2"
    }
  ]
}
```
... ... more
按 JSON 格式返回， 先在 analysis 中分析，再填充 result 结果。
【以上简化版提示词仅仅参考示例】</code></pre></div><p >通过上面的评估 + 自动化收集的策略，我们发现 AI 生成的知识，比业务提供的知识更有效，在整体平均得分会提高 3-5%。</p><p >但光有自动评估不够，因为评估的标准会影响结果，我们<b>定期把 AI 预测的任务发给业务同学进行打分或者反馈，以此来改进评估本身。</b>比如 AI 的预测可能会从上下游推断出更准确的含义，但人类标注可能会忽略这一点。这种情况单纯的相似度打分是不客观的，可能导致得分低，所以在后续我们改进了多个版本的评估提示词，并补充了更多的上下文信息，让评估更反映真实的情况。</p><p >这种自动评估机制不仅加速了我们的质量控制流程，还提供了持续改进的数据基础。通过分析低分案例，我们能够有针对性地优化提示词和上下文处理逻辑。</p><h2 id="h_1902814743636447932_9" >实践中的挑战与解决方案</h2><p >理论很美好，实践中却处处是挑战和坑。</p><h3 id="h_1902814743636447932_10" >上下文信息过载</h3><p >最初，我们想当然地认为"信息越多越好"，尽可能的把更多的上下文给大 Agent，结果发现一些认为上下文超过一定量后，模型反而表现更差。有时它会被无关信息干扰，平均得分会更低。比如把多层生成 SQL 给到表的描述任务后，整体得分降低。这些是因为不同的任务依赖的上下文信息不一样。 </p><p >我非常喜欢一个比喻，把人类自己想象成是一个有限出窗口的 LLM，当别人扔给你一堆信息后，那些无关紧要的信息占据着你有限的空间，你能更好的完成任务吗？</p><p >解决方法：我们建立了"上下文最优阈值"，通过实验确定各类任务的最佳上下文量。例如：</p><ul><li >表描述任务：最多 N 个字段信息，3-5个血缘关系</li><li >字段描述任务：相关度前 N 的其他字段</li><li >生成 SQL ：仅仅在必要任务下才注入</li></ul><p >这里也反映了评估的重要性，如果我们不建立评估，根本无法跟踪这类效果。</p><h3 id="h_1902814743636447932_11" >风格一致性问题</h3><p >在把模型的预测结果给业务同学检查后，发现业务会在细节上提出一些问题，比如表描述不应该包含具体的字段内容，字段描述不应该包含类型等、字段加工规则不应该包含具体的时间等。</p><p >这些细节不会在评估的分数得分反馈，因为它是一种结果风格类的诉求。</p><p >解决方法很简单：针对特定范围的任务（业务定义的批次），我们在提示词中加入了格式示例和风格指南，引导模型生成风格一致的内容。比如为表描述指定"20字以内不要生成 xxx ，应该生成 yyy"，再添加几个 few shot 基本能控制整体格式要求。</p><p >但要注意的是，这里在架构上需要保持灵活性，某类任务的提示词能支持可配置性，这也是我们花费了大量时间在评估管理台的原因，我们的提示词能根据不同的批次范围动态的配置，<b>每个提示词均能通过 Jinja2 语法动态配置不同的上下文变量</b>，比如领域知识、各种表、字段、血缘上下文信息，以满足快速批量化评估，以及不同业务的个性化需求。</p><h3 id="h_1902814743636447932_12" >处理速度与成本平衡</h3><p >面对百万级表和亿级字段，处理速度和API成本成为不得不考虑的问题。在公司中台 rpm/tpm 限流下，我们需要尽可能的通过技术手段以及跨团队合作解决。</p><ul><li >动态限流机制：实现动态 LLM 网关，根据白天和夜间不同时间段，分配不同的 rpm。</li><li >任务合并：在相同/相似上下文的任务中，复用上下文。合并返回结果。</li><li >缓存结果： 在已经生成的表/字段 ID+ 任务类型中，直接使用缓存。（开关可控，如果结果优化任务，则支持覆盖）</li><li >分批次处理：按业务批次重要性，逐步评估、优化、执行不同的任务范围。这些批次通常是上层业务领域的概念，通常是以部门，系统等为单位。按批次优化处理非常重要，因为实际的元数据补全中，永远只有少数的数据才有业务利用和共享价值，并不需要在全公司范围内处理。</li></ul><h3 id="h_1902814743636447932_13" >实际效果与价值 </h3><p class="content"><br></p><figure ><div><img src="https://pic3.zhimg.com/v2-80f95cfb402b886d5829cd0e098f3df4_1440w.jpg" class="origin_image zh-lightbox-thumb" width="3534" ></div></figure><p >经过一段的开发和优化，最终观察到实际效果在不同批次有显著差异。一些高质量的项目中（第一批次），准确率到达 80% 以上。但更多的批次，准确率在70%-80% 之间。<b>通常在初步评估的批次，可能准确率是 60%+，经过优化提升到70%+非常轻松，但继续把 70% + 的准确率提高到 80%变得异常的困难</b>。 深入到这些案例细节，普遍体现的问题在人工标注的不准确性、表/字段命名以及应用的不规范。这类数据的预测对人类也是挑战，想要继续提升投入会变得更高（比如利用代码，收集更多信息，多伦LLM调用等），但收益不会很明显。</p><p >所以，笔者认为AI任务的优化，最终达到一个合适的边际效益即可。这套系统带来的价值远不止于节省人力（业务预算的数据，节省 76.7 人月）</p><p >1. 数据资产透明化：元数据让业务人员更容易找到所需数据，促进数据共享和价值挖掘</p><p >2. 安全合规提升：更大范围标识敏感数据，降低数据安全风险。</p><p >3. 数据治理基础：为后续的其他工作比如，AI 智能问答，数据质量、数据标准等<b>工作奠定基础</b>。</p><p >有趣的是，系统上线后，一些业务团队甚至反馈"AI生成的描述比原来的人工描述更准确、更全面"。这在某种程度上验证了的多维上下文方法的有效性 ——<b>AI 能够整合分散在多处的信息，生成更全面的理解</b>，而普通的人类在全面理解上将会需要投入更多的思考时间。 但大模型不会简单的替代人类工作，它需要<b>人类用正确的方法、寻找合适的上下文和持续的优化才能发挥最大价值。</b></p><p >如果你也在考虑将LLM应用于数据治理或者相似的任务，希望我们的经验能给你一些启发。记住，上下文是关键，多 Agent专家化是方向，自动评估是保障。</p><p >将 LLM 应用于数据治理的道路很长，而我们才刚刚起步。希望本文能给你一些启发。</p><p >————</p><p >【本文涉及的表名非真实命名，相关业务信息均已脱敏处理】</p><p >——更新v2——<br>补充一张图</p><blockquote >本文使用 <a href="https://zhuanlan.zhihu.com/p/358098152" class="internal" target="_blank">文章同步助手</a> 同步自【混沌随想】</blockquote></div><span id="VirtualCatalogAnchorPoint"></span>

<hr />

<div class="original-link" style="margin-top: 20px; padding: 10px; background-color: #f8f8f8; border-radius: 6px;">
  <p style="margin: 0; font-size: 14px;">📝 本文转载自知乎专栏</p>
  <p style="margin: 5px 0 0; font-size: 14px;">原文链接：<a href="https://zhuanlan.zhihu.com/p/1902814743636447932" target="_blank" rel="noopener noreferrer">点击查看知乎原文</a></p>
  <p style="margin: 5px 0 0; font-size: 14px;">作者：混沌福王</p>
</div>
</div> <div class="copyright" style="font-style: italic;white-space: break-spaces;white-space: normal;font-size:14px;line-height: 1.5;" data-v-d56170a2>
——————<br data-v-d56170a2>
文档信息
<br data-v-d56170a2> <br data-v-d56170a2> <div data-v-d56170a2>标题：<a target="__blank" href="https://imwangfu.com/2025/05/llm-agent-yuan.html" data-v-d56170a2>将 LLM Agent 大规模用于百万级数据治理—「元数据补全」</a></div> <div style="word-break: break-all;" data-v-d56170a2>发表时间：2025年5月5日</div> <div style="word-break: break-all;" data-v-d56170a2>笔名：混沌随想</div> <div style="word-break: break-all;" data-v-d56170a2>原链接：<a target="__blank" href="https://imwangfu.com/2025/05/llm-agent-yuan.html" data-v-d56170a2>https://imwangfu.com/2025/05/llm-agent-yuan.html</a></div> <div style="word-break: break-all;" data-v-d56170a2>版权声明：如需转载，请邮件知会 imwangfu@gmail.com，并保留此文档信息申明</div> <br data-v-d56170a2> <div style="word-break: break-all;" data-v-d56170a2>更多深度随想可以关注公众号：混沌随想</div>
——————
    </div> <div class="wx-qrcode" data-v-d56170a2><img src="/left.png" alt style="width:36%" data-v-d56170a2> <img src="/right.png" alt style="width:64%" data-v-d56170a2></div> <div class="page-edit" data-v-d56170a2><!----> <div class="last-updated" data-v-d56170a2><span class="prefix" data-v-d56170a2>更新时间: </span> <time datetime="1758120940000" class="time" data-v-d56170a2>2025年9月17日, 14:55:40</time></div></div> <!---->  <div id="gitalk-container" data-v-d56170a2></div></div> <div id="disqus_thread" class="blog" data-v-d56170a2></div></div> <!----></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.32403bab.js" defer></script><script src="/assets/js/3.8dc51a7a.js" defer></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script
      async
      src="https://www.googletagmanager.com/gtag/js?id=G-TWXMJ6R199"
    ></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() {
        dataLayer.push(arguments);
      }
      gtag("js", new Date());

      gtag("config", "G-TWXMJ6R199");
    </script>
    <script>
      var _hmt = _hmt || [];
      (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?088b745d5fe1e425c919ebcf4f27bc46";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
      })();
    </script>
  </body>
</html>
